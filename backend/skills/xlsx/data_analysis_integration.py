"""
æ•°æ®åˆ†æä¸ Excel å¯¼å‡ºé›†æˆæ¨¡å—
å°†çœŸå®æ•°æ®ã€8-Agent åˆ†æå’Œ Excel å¯¼å‡ºæ— ç¼è¿æ¥
"""

import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path
import pandas as pd

from agents import (
    OrchestratorAgent,
    MemoryAgent,
    PreprocessorAgent,
    FactGeneratorAgent,
    InterpreterAgent,
    RiskDetectorAgent,
    ActionAdvisorAgent
)
from skills.xlsx import export_analysis_to_excel
from database import DatabaseManager

logger = logging.getLogger(__name__)


class DataAnalysisExporter:
    """
    æ•°æ®åˆ†æå¯¼å‡ºå™¨
    
    åŠŸèƒ½æµç¨‹ï¼š
    1. ä»æ•°æ®åº“/æ–‡ä»¶è¯»å–çœŸå®æ•°æ®
    2. é€šè¿‡ 8-Agent ç³»ç»Ÿè¿›è¡Œæ™ºèƒ½åˆ†æ
    3. ç”Ÿæˆå››è‰²å¡ç‰‡
    4. å¯¼å‡ºä¸ºä¸“ä¸š Excel æŠ¥å‘Š
    """
    
    def __init__(
        self,
        db_manager: DatabaseManager,
        orchestrator: OrchestratorAgent,
        memory: MemoryAgent
    ):
        """
        åˆå§‹åŒ–å¯¼å‡ºå™¨
        
        Args:
            db_manager: æ•°æ®åº“ç®¡ç†å™¨
            orchestrator: æ€»æŒ‡æŒ¥ Agent
            memory: è®°å¿† Agent
        """
        self.db = db_manager
        self.orchestrator = orchestrator
        self.memory = memory
        
        # åˆå§‹åŒ–å„ä¸ªä¸“ä¸š Agent
        self.preprocessor = PreprocessorAgent()
        
        # éœ€è¦ API é…ç½®çš„ Agentï¼Œä½¿ç”¨ try-except å¤„ç†
        try:
            from config import settings
            api_base = "http://localhost:8000"
            model_path = str(settings.MODEL_PATH) if hasattr(settings, 'MODEL_PATH') else ""
            
            self.fact_generator = FactGeneratorAgent(
                genie_api_base_url=api_base,
                model_path=model_path
            )
            self.interpreter = InterpreterAgent(
                genie_api_base_url=api_base,
                model_path=model_path
            )
            self.risk_detector = RiskDetectorAgent(
                genie_api_base_url=api_base,
                model_path=model_path
            )
            self.action_advisor = ActionAdvisorAgent(
                genie_api_base_url=api_base,
                model_path=model_path
            )
        except Exception as e:
            logger.warning(f"Agent åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬: {e}")
            self.fact_generator = None
            self.interpreter = None
            self.risk_detector = None
            self.action_advisor = None
        
        logger.info("[DataAnalysisExporter] åˆå§‹åŒ–å®Œæˆ")
    
    async def analyze_and_export(
        self,
        data_source: str,
        query: str,
        output_path: str,
        include_charts: bool = True
    ) -> Dict[str, Any]:
        """
        å®Œæ•´çš„åˆ†æå’Œå¯¼å‡ºæµç¨‹
        
        Args:
            data_source: æ•°æ®æºï¼ˆæ–‡ä»¶è·¯å¾„æˆ–æ•°æ®åº“è¡¨åï¼‰
            query: ç”¨æˆ·æŸ¥è¯¢/åˆ†æéœ€æ±‚
            output_path: Excel è¾“å‡ºè·¯å¾„
            include_charts: æ˜¯å¦åŒ…å«å›¾è¡¨
        
        Returns:
            ç»“æœå­—å…¸ï¼ŒåŒ…å«åˆ†æç»“æœå’Œå¯¼å‡ºè·¯å¾„
        """
        logger.info(f"[DataAnalysisExporter] å¼€å§‹åˆ†æ: {query}")
        logger.info(f"[DataAnalysisExporter] æ•°æ®æº: {data_source}")
        
        try:
            # ========== æ­¥éª¤ 1: åŠ è½½çœŸå®æ•°æ® ==========
            data = await self._load_data(data_source)
            logger.info(f"[DataAnalysisExporter] æ•°æ®åŠ è½½å®Œæˆ: {len(data)} è¡Œ")
            
            # ========== æ­¥éª¤ 2: æ•°æ®é¢„å¤„ç† ==========
            preprocessed = await self._preprocess_data(data, query)
            logger.info(f"[DataAnalysisExporter] æ•°æ®é¢„å¤„ç†å®Œæˆ")
            
            # ========== æ­¥éª¤ 3: 8-Agent æ™ºèƒ½åˆ†æ ==========
            analysis_result = await self._run_agent_analysis(
                data=preprocessed,
                query=query
            )
            logger.info(f"[DataAnalysisExporter] Agent åˆ†æå®Œæˆ")
            
            # ========== æ­¥éª¤ 4: ç”Ÿæˆå››è‰²å¡ç‰‡ ==========
            cards_by_type = await self._generate_cards(analysis_result)
            logger.info(f"[DataAnalysisExporter] å¡ç‰‡ç”Ÿæˆå®Œæˆ")
            
            # ========== æ­¥éª¤ 5: å‡†å¤‡ Excel æ•°æ® ==========
            excel_data = await self._prepare_excel_data(
                data=data,
                preprocessed=preprocessed,
                cards_by_type=cards_by_type,
                include_charts=include_charts
            )
            logger.info(f"[DataAnalysisExporter] Excel æ•°æ®å‡†å¤‡å®Œæˆ")
            
            # ========== æ­¥éª¤ 6: å¯¼å‡º Excel æŠ¥å‘Š ==========
            export_result = await self._export_to_excel(
                output_path=output_path,
                excel_data=excel_data,
                query=query
            )
            logger.info(f"[DataAnalysisExporter] Excel å¯¼å‡ºå®Œæˆ: {output_path}")
            
            # ========== æ­¥éª¤ 7: ä¿å­˜åˆ°è®°å¿†åº“ ==========
            await self._save_to_memory(cards_by_type, query)
            logger.info(f"[DataAnalysisExporter] ä¿å­˜åˆ°è®°å¿†åº“å®Œæˆ")
            
            return {
                "status": "success",
                "output_path": output_path,
                "cards_count": sum(len(cards) for cards in cards_by_type.values()),
                "data_rows": len(data),
                "analysis_result": analysis_result,
                "excel_data": excel_data
            }
            
        except Exception as e:
            logger.error(f"[DataAnalysisExporter] åˆ†æå¯¼å‡ºå¤±è´¥: {e}", exc_info=True)
            raise
    
    async def _load_data(self, data_source: str) -> pd.DataFrame:
        """
        åŠ è½½çœŸå®æ•°æ®
        
        æ”¯æŒï¼š
        - CSV/Excel æ–‡ä»¶
        - æ•°æ®åº“è¡¨
        - DuckDB æŸ¥è¯¢
        """
        if data_source.endswith('.csv'):
            # CSV æ–‡ä»¶
            return pd.read_csv(data_source)
        
        elif data_source.endswith(('.xlsx', '.xls')):
            # Excel æ–‡ä»¶
            return pd.read_excel(data_source)
        
        elif data_source.startswith('db:'):
            # æ•°æ®åº“è¡¨
            table_name = data_source.replace('db:', '')
            # ä»æ•°æ®åº“è¯»å–
            # è¿™é‡Œéœ€è¦æ ¹æ®æ‚¨çš„æ•°æ®åº“ç»“æ„è°ƒæ•´
            query = f"SELECT * FROM {table_name}"
            # å‡è®¾ä½¿ç”¨ DuckDB
            import duckdb
            conn = duckdb.connect(str(self.db.db_path))
            df = conn.execute(query).fetchdf()
            conn.close()
            return df
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æºæ ¼å¼: {data_source}")
    
    async def _preprocess_data(
        self, 
        data: pd.DataFrame, 
        query: str
    ) -> Dict[str, Any]:
        """
        æ•°æ®é¢„å¤„ç†
        
        ä½¿ç”¨ PreprocessorAgent (å¯†å·æˆ¿) è¿›è¡Œæ•°æ®æ¸…æ´—å’Œç‰¹å¾æå–
        """
        # åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
        stats = {
            "row_count": len(data),
            "column_count": len(data.columns),
            "columns": list(data.columns),
            "dtypes": data.dtypes.to_dict(),
            "missing_values": data.isnull().sum().to_dict(),
            "numeric_summary": data.describe().to_dict() if len(data.select_dtypes(include='number').columns) > 0 else {}
        }
        
        # ä½¿ç”¨ Agent è¿›è¡Œæ™ºèƒ½é¢„å¤„ç†
        try:
            preprocessed = await self.preprocessor.preprocess_data(
                data_source="memory",  # ä»å†…å­˜æ•°æ®å¤„ç†
                data_type="dataframe"
            )
        except Exception as e:
            logger.warning(f"é¢„å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®: {e}")
            preprocessed = {
                "data": data.to_dict('records'),
                "query": query,
                "stats": stats
            }
        
        return {
            "original_data": data,
            "stats": stats,
            "preprocessed": preprocessed
        }
    
    async def _run_agent_analysis(
        self,
        data: Dict[str, Any],
        query: str
    ) -> Dict[str, Any]:
        """
        è¿è¡Œ 8-Agent åä½œåˆ†æ
        
        æµç¨‹ï¼š
        1. é”¦è¡£å«æ€»æŒ‡æŒ¥ä½¿ - ä»»åŠ¡åˆ†è§£
        2. å¯†å·æˆ¿ - æ•°æ®é¢„å¤„ç†
        3. é€šæ”¿å¸ - äº‹å®æå–
        4. ç›‘å¯Ÿé™¢ - è§£é‡Šç”Ÿæˆ
        5. åˆ‘ç‹±å¸ - é£é™©è¯†åˆ«
        6. å‚è°‹å¸ - è¡ŒåŠ¨å»ºè®®
        7. å¤ªå²é˜ - çŸ¥è¯†å­˜å‚¨
        8. é©¿ä¼ å¸ - ç»“æœæ•´åˆ
        """
        # æ„å»ºä»»åŠ¡è¯·æ±‚
        task_request = {
            "raw_material": str(data['stats']),
            "user_query": query,
            "request_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # 1. ä»»åŠ¡åˆ†è§£
        task_instructions = self.orchestrator.parse_user_request(task_request)
        
        # 2. ä¸‹å‘ä»»åŠ¡
        dispatch_result = self.orchestrator.dispatch_task(task_instructions)
        
        # 3. ç›‘æ§æ‰§è¡Œ
        task_ids = dispatch_result.get('task_ids', [])
        status_report = self.orchestrator.monitor_agent_status(task_ids)
        
        # 4. æ”¶é›†ç»“æœ
        all_results = self.orchestrator.receive_all_results(task_ids)
        
        return {
            "task_id": task_instructions['task_id'],
            "dispatch_result": dispatch_result,
            "status_report": status_report,
            "agent_results": all_results
        }
    
    async def _generate_cards(
        self,
        analysis_result: Dict[str, Any]
    ) -> Dict[str, List[Dict[str, Any]]]:
        """
        ç”Ÿæˆå››è‰²å¡ç‰‡
        
        ä» Agent åˆ†æç»“æœä¸­æå–å¹¶æ ¼å¼åŒ–ä¸ºæ ‡å‡†å¡ç‰‡æ ¼å¼
        """
        agent_results = analysis_result.get('agent_results', {})
        
        cards_by_type = {
            'fact': [],
            'interpret': [],
            'risk': [],
            'action': []
        }
        
        # ğŸ”µ è“è‰²å¡ç‰‡ - äº‹å®ï¼ˆé€šæ”¿å¸ï¼‰
        tongzhengsi_result = agent_results.get('tongzhengsi', {})
        if tongzhengsi_result:
            facts = tongzhengsi_result.get('facts', [])
            for idx, fact in enumerate(facts):
                cards_by_type['fact'].append({
                    "id": f"fact_{datetime.now().strftime('%Y%m%d%H%M%S')}_{idx}",
                    "title": fact.get('title', 'æ•°æ®äº‹å®'),
                    "content": fact.get('content', ''),
                    "confidence": fact.get('confidence', 0.9),
                    "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "tags": fact.get('tags', ['æ•°æ®', 'äº‹å®']),
                    "source": "é€šæ”¿å¸"
                })
        
        # ğŸŸ¢ ç»¿è‰²å¡ç‰‡ - è§£é‡Šï¼ˆç›‘å¯Ÿé™¢ï¼‰
        jianchayuan_result = agent_results.get('jianchayuan', {})
        if jianchayuan_result:
            interpretations = jianchayuan_result.get('interpretations', [])
            for idx, interp in enumerate(interpretations):
                cards_by_type['interpret'].append({
                    "id": f"interpret_{datetime.now().strftime('%Y%m%d%H%M%S')}_{idx}",
                    "title": interp.get('title', 'åŸå› åˆ†æ'),
                    "content": interp.get('content', ''),
                    "confidence": interp.get('confidence', 0.85),
                    "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "tags": interp.get('tags', ['åˆ†æ', 'è§£é‡Š']),
                    "source": "ç›‘å¯Ÿé™¢"
                })
        
        # ğŸŸ¡ é»„è‰²å¡ç‰‡ - é£é™©ï¼ˆåˆ‘ç‹±å¸ï¼‰
        xingyusi_result = agent_results.get('xingyusi', {})
        if xingyusi_result:
            risks = xingyusi_result.get('risks', [])
            for idx, risk in enumerate(risks):
                cards_by_type['risk'].append({
                    "id": f"risk_{datetime.now().strftime('%Y%m%d%H%M%S')}_{idx}",
                    "title": risk.get('title', 'é£é™©é¢„è­¦'),
                    "content": risk.get('content', ''),
                    "confidence": risk.get('confidence', 0.88),
                    "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "tags": risk.get('tags', ['é£é™©', 'é¢„è­¦']),
                    "risk_level": risk.get('level', 'ä¸­'),
                    "source": "åˆ‘ç‹±å¸"
                })
        
        # ğŸ”´ çº¢è‰²å¡ç‰‡ - è¡ŒåŠ¨ï¼ˆå‚è°‹å¸ï¼‰
        canmousi_result = agent_results.get('canmousi', {})
        if canmousi_result:
            actions = canmousi_result.get('actions', [])
            for idx, action in enumerate(actions):
                cards_by_type['action'].append({
                    "id": f"action_{datetime.now().strftime('%Y%m%d%H%M%S')}_{idx}",
                    "title": action.get('title', 'è¡ŒåŠ¨å»ºè®®'),
                    "content": action.get('content', ''),
                    "confidence": action.get('confidence', 0.87),
                    "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "tags": action.get('tags', ['è¡ŒåŠ¨', 'å»ºè®®']),
                    "priority": action.get('priority', 'ä¸­'),
                    "source": "å‚è°‹å¸"
                })
        
        return cards_by_type
    
    async def _prepare_excel_data(
        self,
        data: pd.DataFrame,
        preprocessed: Dict[str, Any],
        cards_by_type: Dict[str, List[Dict[str, Any]]],
        include_charts: bool
    ) -> Dict[str, Any]:
        """
        å‡†å¤‡ Excel å¯¼å‡ºæ•°æ®
        """
        # åˆ†æä¿¡æ¯
        analysis_info = {
            "title": f"Antinet æ™ºèƒ½åˆ†ææŠ¥å‘Š",
            "date": datetime.now().strftime("%Y-%m-%d"),
            "data_source": "çœŸå®ä¸šåŠ¡æ•°æ®",
            "card_counts": {
                card_type: len(cards)
                for card_type, cards in cards_by_type.items()
            },
            "summary": self._generate_summary(cards_by_type)
        }
        
        # æ•°æ®å·¥ä½œè¡¨
        data_sheets = {
            "åŸå§‹æ•°æ®": data.head(1000),  # é™åˆ¶è¡Œæ•°é¿å…æ–‡ä»¶è¿‡å¤§
            "æ•°æ®ç»Ÿè®¡": pd.DataFrame(preprocessed['stats']['numeric_summary'])
        }
        
        # å›¾è¡¨æ•°æ®
        charts = []
        if include_charts:
            charts = self._generate_charts(data, cards_by_type)
        
        return {
            "analysis_info": analysis_info,
            "cards_by_type": cards_by_type,
            "data_sheets": data_sheets,
            "charts": charts
        }
    
    def _generate_summary(
        self,
        cards_by_type: Dict[str, List[Dict[str, Any]]]
    ) -> str:
        """ç”ŸæˆæŠ¥å‘Šæ‘˜è¦"""
        total_cards = sum(len(cards) for cards in cards_by_type.values())
        
        summary_parts = [
            f"æœ¬æŠ¥å‘ŠåŸºäºçœŸå®ä¸šåŠ¡æ•°æ®è¿›è¡Œæ™ºèƒ½åˆ†æï¼Œ",
            f"é€šè¿‡ 8-Agent åä½œç³»ç»Ÿç”Ÿæˆäº† {total_cards} å¼ å››è‰²å¡ç‰‡ã€‚"
        ]
        
        if cards_by_type['fact']:
            summary_parts.append(
                f"å‘ç° {len(cards_by_type['fact'])} ä¸ªå…³é”®æ•°æ®äº‹å®ï¼Œ"
            )
        
        if cards_by_type['risk']:
            summary_parts.append(
                f"è¯†åˆ« {len(cards_by_type['risk'])} é¡¹æ½œåœ¨é£é™©ï¼Œ"
            )
        
        if cards_by_type['action']:
            summary_parts.append(
                f"æå‡º {len(cards_by_type['action'])} é¡¹å¯æ‰§è¡Œå»ºè®®ã€‚"
            )
        
        return "".join(summary_parts)
    
    def _generate_charts(
        self,
        data: pd.DataFrame,
        cards_by_type: Dict[str, List[Dict[str, Any]]]
    ) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå›¾è¡¨æ•°æ®"""
        charts = []
        
        # å›¾è¡¨ 1: å¡ç‰‡åˆ†å¸ƒ
        chart_data = pd.DataFrame({
            "ç±»å‹": ["äº‹å®", "è§£é‡Š", "é£é™©", "è¡ŒåŠ¨"],
            "æ•°é‡": [
                len(cards_by_type['fact']),
                len(cards_by_type['interpret']),
                len(cards_by_type['risk']),
                len(cards_by_type['action'])
            ]
        })
        
        charts.append({
            "name": "å¡ç‰‡åˆ†å¸ƒ",
            "type": "bar",
            "title": "å››è‰²å¡ç‰‡åˆ†å¸ƒç»Ÿè®¡",
            "data": chart_data,
            "x_col": "ç±»å‹",
            "y_cols": ["æ•°é‡"]
        })
        
        # å›¾è¡¨ 2: æ•°æ®è¶‹åŠ¿ï¼ˆå¦‚æœæœ‰æ—¶é—´åˆ—ï¼‰
        if 'date' in data.columns or 'æ—¥æœŸ' in data.columns:
            date_col = 'date' if 'date' in data.columns else 'æ—¥æœŸ'
            numeric_cols = data.select_dtypes(include='number').columns[:3]  # å–å‰3ä¸ªæ•°å€¼åˆ—
            
            if len(numeric_cols) > 0:
                trend_data = data[[date_col] + list(numeric_cols)].copy()
                trend_data = trend_data.groupby(date_col).mean().reset_index()
                
                charts.append({
                    "name": "æ•°æ®è¶‹åŠ¿",
                    "type": "line",
                    "title": "å…³é”®æŒ‡æ ‡è¶‹åŠ¿åˆ†æ",
                    "data": trend_data,
                    "x_col": date_col,
                    "y_cols": list(numeric_cols)
                })
        
        return charts
    
    async def _export_to_excel(
        self,
        output_path: str,
        excel_data: Dict[str, Any],
        query: str
    ) -> str:
        """å¯¼å‡ºåˆ° Excel"""
        return export_analysis_to_excel(
            output_path=output_path,
            analysis_info=excel_data['analysis_info'],
            cards_by_type=excel_data['cards_by_type'],
            data_sheets=excel_data['data_sheets'],
            charts=excel_data['charts']
        )
    
    async def _save_to_memory(
        self,
        cards_by_type: Dict[str, List[Dict[str, Any]]],
        query: str
    ):
        """ä¿å­˜åˆ°è®°å¿†åº“ï¼ˆå¤ªå²é˜ï¼‰"""
        for card_type, cards in cards_by_type.items():
            for card in cards:
                self.memory.store_card({
                    **card,
                    "type": card_type,
                    "query": query
                })


# ==================== ä¾¿æ·å‡½æ•° ====================

async def quick_analyze_and_export(
    data_source: str,
    query: str,
    output_path: str,
    db_manager: DatabaseManager,
    orchestrator: OrchestratorAgent,
    memory: MemoryAgent
) -> Dict[str, Any]:
    """
    å¿«é€Ÿåˆ†æå’Œå¯¼å‡º
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
    ```python
    result = await quick_analyze_and_export(
        data_source="./data/sales_data.csv",
        query="åˆ†æä¸Šä¸ªæœˆçš„é”€å”®è¶‹åŠ¿å’Œé£é™©",
        output_path="./exports/sales_analysis.xlsx",
        db_manager=db_manager,
        orchestrator=orchestrator,
        memory=memory
    )
    ```
    """
    exporter = DataAnalysisExporter(db_manager, orchestrator, memory)
    return await exporter.analyze_and_export(
        data_source=data_source,
        query=query,
        output_path=output_path
    )
