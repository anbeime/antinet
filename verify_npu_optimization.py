"""
NPU ä¼˜åŒ–æ•ˆæœå¿«é€ŸéªŒè¯è„šæœ¬
æµ‹è¯•ä¼˜åŒ–åçš„æ¨ç†æ€§èƒ½
"""
import sys
import time
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_npu_optimization():
    """æµ‹è¯• NPU ä¼˜åŒ–æ•ˆæœ"""
    
    print("=" * 70)
    print("NPU æ€§èƒ½ä¼˜åŒ–éªŒè¯æµ‹è¯•")
    print("=" * 70)
    
    try:
        # å¯¼å…¥æ¨¡å‹åŠ è½½å™¨
        logger.info("å¯¼å…¥æ¨¡å‹åŠ è½½å™¨...")
        from backend.models.model_loader import get_model_loader
        
        # è·å–æ¨¡å‹åŠ è½½å™¨å®ä¾‹
        logger.info("è·å–æ¨¡å‹åŠ è½½å™¨å®ä¾‹...")
        loader = get_model_loader()
        
        # åŠ è½½æ¨¡å‹
        logger.info("åŠ è½½æ¨¡å‹åˆ° NPU...")
        start_load = time.time()
        model = loader.load()
        load_time = time.time() - start_load
        logger.info(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f}s")
        
        # æµ‹è¯•ç”¨ä¾‹
        test_cases = [
            {
                "name": "å¿«é€Ÿé—®ç­”",
                "prompt": "ä»€ä¹ˆæ˜¯AI PCï¼Ÿ",
                "max_tokens": 64,
                "expected_time": 500
            },
            {
                "name": "æ•°æ®åˆ†æ",
                "prompt": "åˆ†æä¸€ä¸‹ç«¯ä¾§AIçš„ä¼˜åŠ¿",
                "max_tokens": 64,
                "expected_time": 500
            },
            {
                "name": "ç®€çŸ­å¯¹è¯",
                "prompt": "ä½ å¥½",
                "max_tokens": 32,
                "expected_time": 300
            }
        ]
        
        results = []
        
        print("\n" + "=" * 70)
        print("å¼€å§‹æ¨ç†æ€§èƒ½æµ‹è¯•")
        print("=" * 70)
        
        for i, test in enumerate(test_cases, 1):
            print(f"\næµ‹è¯• {i}/{len(test_cases)}: {test['name']}")
            print(f"æç¤ºè¯: {test['prompt']}")
            print(f"Token æ•°: {test['max_tokens']}")
            print(f"æœŸæœ›å»¶è¿Ÿ: < {test['expected_time']}ms")
            print("-" * 70)
            
            try:
                # æ‰§è¡Œæ¨ç†
                start_time = time.time()
                result = loader.infer(
                    prompt=test['prompt'],
                    max_new_tokens=test['max_tokens']
                )
                inference_time = (time.time() - start_time) * 1000
                
                # åˆ¤æ–­æ˜¯å¦é€šè¿‡
                passed = inference_time < test['expected_time']
                status = "âœ… é€šè¿‡" if passed else "âŒ æœªé€šè¿‡"
                
                print(f"æ¨ç†å»¶è¿Ÿ: {inference_time:.2f}ms")
                print(f"æµ‹è¯•ç»“æœ: {status}")
                print(f"ç”Ÿæˆå†…å®¹: {result[:100]}...")
                
                results.append({
                    "name": test['name'],
                    "inference_time": inference_time,
                    "expected_time": test['expected_time'],
                    "passed": passed
                })
                
            except Exception as e:
                logger.error(f"âŒ æ¨ç†å¤±è´¥: {e}")
                results.append({
                    "name": test['name'],
                    "inference_time": None,
                    "expected_time": test['expected_time'],
                    "passed": False,
                    "error": str(e)
                })
        
        # æ±‡æ€»ç»“æœ
        print("\n" + "=" * 70)
        print("æµ‹è¯•ç»“æœæ±‡æ€»")
        print("=" * 70)
        
        passed_count = sum(1 for r in results if r['passed'])
        total_count = len(results)
        
        print(f"\né€šè¿‡ç‡: {passed_count}/{total_count} ({passed_count/total_count*100:.1f}%)")
        print("\nè¯¦ç»†ç»“æœ:")
        
        for r in results:
            if r.get('error'):
                print(f"  âŒ {r['name']}: é”™è¯¯ - {r['error']}")
            else:
                status = "âœ…" if r['passed'] else "âŒ"
                print(f"  {status} {r['name']}: {r['inference_time']:.2f}ms (æœŸæœ› < {r['expected_time']}ms)")
        
        # æ€§èƒ½ç»Ÿè®¡
        valid_times = [r['inference_time'] for r in results if r['inference_time'] is not None]
        if valid_times:
            avg_time = sum(valid_times) / len(valid_times)
            min_time = min(valid_times)
            max_time = max(valid_times)
            
            print("\næ€§èƒ½ç»Ÿè®¡:")
            print(f"  å¹³å‡å»¶è¿Ÿ: {avg_time:.2f}ms")
            print(f"  æœ€å¿«å»¶è¿Ÿ: {min_time:.2f}ms")
            print(f"  æœ€æ…¢å»¶è¿Ÿ: {max_time:.2f}ms")
        
        # ä¼˜åŒ–æ•ˆæœè¯„ä¼°
        print("\n" + "=" * 70)
        print("ä¼˜åŒ–æ•ˆæœè¯„ä¼°")
        print("=" * 70)
        
        if passed_count == total_count:
            print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼NPU ä¼˜åŒ–æ•ˆæœæ˜¾è‘—ï¼")
            print("   - BURST æ¨¡å¼å·²ç”Ÿæ•ˆ")
            print("   - Token ä¼˜åŒ–å·²ç”Ÿæ•ˆ")
            print("   - æ¨ç†æ€§èƒ½è¾¾æ ‡")
        elif passed_count > 0:
            print("âš ï¸  éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œä¼˜åŒ–æ•ˆæœä¸€èˆ¬")
            print("   å»ºè®®æ£€æŸ¥:")
            print("   - NPU é©±åŠ¨çŠ¶æ€")
            print("   - QNN backend é…ç½®")
            print("   - æ¨¡å‹é‡åŒ–ç‰ˆæœ¬")
        else:
            print("âŒ æ‰€æœ‰æµ‹è¯•æœªé€šè¿‡ï¼Œä¼˜åŒ–æ•ˆæœä¸ä½³")
            print("   è¯·æ£€æŸ¥:")
            print("   - åç«¯æœåŠ¡æ˜¯å¦é‡å¯")
            print("   - NPU æ˜¯å¦æ­£å¸¸å·¥ä½œ")
            print("   - æŸ¥çœ‹åç«¯æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯")
        
        print("\n" + "=" * 70)
        
        return passed_count == total_count
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("\nğŸš€ å¼€å§‹ NPU ä¼˜åŒ–éªŒè¯æµ‹è¯•...\n")
    
    success = test_npu_optimization()
    
    print("\n" + "=" * 70)
    if success:
        print("âœ… éªŒè¯å®Œæˆï¼šNPU ä¼˜åŒ–æˆåŠŸï¼")
        sys.exit(0)
    else:
        print("âŒ éªŒè¯å®Œæˆï¼šNPU ä¼˜åŒ–éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´")
        sys.exit(1)
